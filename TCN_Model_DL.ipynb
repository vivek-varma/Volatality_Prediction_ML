{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNDg+/8WlXTej2OLaTuDL7r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vivek-varma/Volatality_Prediction_ML/blob/main/TCN_Model_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gWxqlSE_9Bzv"
      },
      "outputs": [],
      "source": [
        "!pip -q install torch torchvision torchaudio\n",
        "\n",
        "import os, math, json, numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import balanced_accuracy_score, f1_score, classification_report, confusion_matrix, log_loss\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from google.colab import drive\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LEN     = 60        # lookback days\n",
        "EPOCHS      = 500\n",
        "BATCH_TRAIN = 128\n",
        "BATCH_EVAL  = 256\n",
        "PATIENCE    = 200\n",
        "SEED        = 1337\n",
        "\n",
        "DATA_DIR = \"/content/drive/MyDrive/Regime_pred/Data\"\n",
        "OUT_DIR  = \"/content/drive/MyDrive/Regime_pred/Models/Deep_TCN\"\n",
        "CSV_PATH = f\"{DATA_DIR}/REGIME_FEATURES_DAILY_LABELED.csv\""
      ],
      "metadata": {
        "id": "exNNu6hT9O3f"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=False)\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "def set_seed(seed=SEED):\n",
        "    import random, numpy as np, torch\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed); torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "set_seed(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGTOPyPV-AZE",
        "outputId": "b57c5baa-d410-44aa-d1bd-bede5e5ad9d7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(CSV_PATH, parse_dates=[\"date\"]).sort_values(\"date\").reset_index(drop=True)\n",
        "print(\"Rows:\", len(df), \"| Date range:\", df.date.min().date(), \"→\", df.date.max().date())\n",
        "print(\"Class counts:\", df[\"regime_y\"].value_counts().to_dict())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HST6gN0n-GJ6",
        "outputId": "77e866b4-12a5-432f-f1d7-689408baaef2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 3478 | Date range: 2018-01-08 → 2024-12-31\n",
            "Class counts: {2: 1182, 0: 1148, 1: 1148}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drop_cols = [\"date\", \"regime_y\", \"RV_t1\"]\n",
        "X = df.drop(columns=[c for c in drop_cols if c in df.columns]).copy()\n",
        "y = df[\"regime_y\"].astype(int).values\n"
      ],
      "metadata": {
        "id": "xahI6CZB-UYM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obj_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "for c in obj_cols:\n",
        "    X[c] = X[c].astype(\"category\").cat.codes.replace(-1, np.nan)\n",
        "\n",
        "# Fill small gaps safely\n",
        "X = X.fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
        "feature_names = X.columns.tolist()\n",
        "X = X.values.astype(np.float32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5LuCPCv-Y1y",
        "outputId": "153bd0a8-1bf8-4f42-8914-bd9ce7e867dd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-529496445.py:6: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  X = X.fillna(method=\"ffill\").fillna(method=\"bfill\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = len(df)\n",
        "n_train = int(math.floor(n * 0.60))\n",
        "n_val   = int(math.floor(n * 0.20))\n",
        "idx_train = np.arange(0, n_train)\n",
        "idx_val   = np.arange(n_train, n_train + n_val)\n",
        "idx_test  = np.arange(n_train + n_val, n)\n"
      ],
      "metadata": {
        "id": "PUqpmD_s-cM8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # lookback days\n",
        "\n",
        "def make_sequences(Xa, ya, idx):\n",
        "    xs, ys, keep_dates = [], [], []\n",
        "    for i in idx:\n",
        "        if i - SEQ_LEN + 1 < 0:\n",
        "            continue\n",
        "        xs.append(Xa[i-SEQ_LEN+1:i+1, :])  # [SEQ_LEN, n_feat]\n",
        "        ys.append(ya[i])\n",
        "        keep_dates.append(df.iloc[i][\"date\"])\n",
        "    return np.stack(xs), np.array(ys), pd.to_datetime(keep_dates)\n",
        "\n",
        "# Standardize using TRAIN ONLY\n",
        "std_scaler = StandardScaler()\n",
        "std_scaler.fit(X[idx_train])\n",
        "Xz = std_scaler.transform(X).astype(np.float32)\n",
        "\n",
        "Xtr_seq, ytr, dates_tr = make_sequences(Xz, y, idx_train)\n",
        "Xva_seq, yva, dates_va = make_sequences(Xz, y, idx_val)\n",
        "Xte_seq, yte, dates_te = make_sequences(Xz, y, idx_test)\n",
        "\n",
        "print(\"Sequences:\", \"Train\", Xtr_seq.shape, \"| Val\", Xva_seq.shape, \"| Test\", Xte_seq.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaYJdh_zEgyc",
        "outputId": "628d14fd-efa0-485d-a1ff-44bb9ba0e932"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequences: Train (2027, 60, 22) | Val (695, 60, 22) | Test (697, 60, 22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sequences -> Train:\", Xtr_seq.shape, \"| Val:\", Xva_seq.shape, \"| Test:\", Xte_seq.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0S9i5kC-w7k",
        "outputId": "128c6d45-ac16-4383-d372-bef76c50c590"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequences -> Train: (2027, 60, 22) | Val: (695, 60, 22) | Test: (697, 60, 22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SeqDS(Dataset):\n",
        "    def __init__(self, Xseq, y):\n",
        "        # Convert to [N, C, T] for Conv1d (channels-first)\n",
        "        self.X = torch.from_numpy(Xseq).permute(0, 2, 1).contiguous()\n",
        "        self.y = torch.from_numpy(y).long()\n",
        "    def __len__(self): return len(self.y)\n",
        "    def __getitem__(self, i): return self.X[i], self.y[i]\n",
        "\n",
        "train_ds = SeqDS(Xtr_seq, ytr)\n",
        "val_ds   = SeqDS(Xva_seq, yva)\n",
        "test_ds  = SeqDS(Xte_seq, yte)\n",
        "\n",
        "BATCH = 64\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True, drop_last=False, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=128, shuffle=False, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=128, shuffle=False, pin_memory=True)\n"
      ],
      "metadata": {
        "id": "EZe07do1Eorb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Chomp1d(nn.Module):\n",
        "    def __init__(self, chomp_size): super().__init__(); self.chomp_size = chomp_size\n",
        "    def forward(self, x): return x[:, :, :-self.chomp_size].contiguous()\n",
        "\n",
        "class TemporalBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, k, dilation, padding, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(in_ch, out_ch, k, padding=padding, dilation=dilation)\n",
        "        self.chomp1 = Chomp1d(padding)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.drop1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(out_ch, out_ch, k, padding=padding, dilation=dilation)\n",
        "        self.chomp2 = Chomp1d(padding)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.drop2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.downsample = nn.Conv1d(in_ch, out_ch, 1) if in_ch != out_ch else None\n",
        "        self.final_relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.conv1(x); y = self.chomp1(y); y = self.relu1(y); y = self.drop1(y)\n",
        "        y = self.conv2(y); y = self.chomp2(y); y = self.relu2(y); y = self.drop2(y)\n",
        "        res = x if self.downsample is None else self.downsample(x)\n",
        "        return self.final_relu(y + res)\n",
        "\n",
        "class TCN(nn.Module):\n",
        "    def __init__(self, in_ch, num_classes, channels=(64,64,64), k=3, dropout=0.1):\n",
        "        super().__init__()\n",
        "        layers, ch_in = [], in_ch\n",
        "        for i, ch_out in enumerate(channels):\n",
        "            dilation = 2 ** i\n",
        "            padding = (k - 1) * dilation\n",
        "            layers.append(TemporalBlock(ch_in, ch_out, k, dilation, padding, dropout))\n",
        "            ch_in = ch_out\n",
        "        self.backbone = nn.Sequential(*layers)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool1d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(ch_in, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(64, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.backbone(x)\n",
        "        return self.head(z)"
      ],
      "metadata": {
        "id": "93SR176j-94P"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "num_classes = int(np.unique(y).size)\n",
        "model = TCN(in_ch=Xtr_seq.shape[2], num_classes=num_classes, channels=(64,64,64), k=3, dropout=0.10).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30fKKOlUCGW2",
        "outputId": "d40f2b5d-9f71-461b-a701-79813fab0623"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes_sorted = np.sort(np.unique(ytr))\n",
        "cls_weights = compute_class_weight(class_weight=\"balanced\", classes=classes_sorted, y=ytr)\n",
        "# Map weights into a dense tensor indexed by class id (0..num_classes-1)\n",
        "w_vec = np.zeros(num_classes, dtype=np.float32)\n",
        "for i, c in enumerate(classes_sorted): w_vec[int(c)] = cls_weights[i]\n",
        "criterion = nn.CrossEntropyLoss(weight=torch.tensor(w_vec, dtype=torch.float32, device=device))\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-3, weight_decay=1e-4)\n",
        "sched = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
        "\n",
        "# Mixed precision for GPU speed\n",
        "amp_scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hxg0Exp2CHZ9",
        "outputId": "053e9a87-7b69-4ba6-b0ac-18fb8bfd6cb9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-325629885.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  amp_scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_loader(loader):\n",
        "    model.eval()\n",
        "    ys, ps = [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in loader:\n",
        "            xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)\n",
        "            with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
        "                logits = model(xb)\n",
        "                prob = torch.softmax(logits, dim=1)\n",
        "            ys.append(yb.cpu().numpy())\n",
        "            ps.append(prob.cpu().numpy())\n",
        "    y_true = np.concatenate(ys)\n",
        "    p = np.concatenate(ps)\n",
        "    y_pred = p.argmax(1)\n",
        "    return y_true, y_pred, p\n",
        "\n",
        "best_val = np.inf\n",
        "patience = 20\n",
        "wait = 0\n",
        "best_path = os.path.join(OUT_DIR, \"tcn_best.pt\")"
      ],
      "metadata": {
        "id": "ps-xmWUzCg1E"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_loader(loader):\n",
        "    model.eval()\n",
        "    ys, ps = [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in loader:\n",
        "            xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)\n",
        "            # New autocast API\n",
        "            with torch.amp.autocast(\"cuda\", enabled=torch.cuda.is_available()):\n",
        "                logits = model(xb)\n",
        "                prob = torch.softmax(logits, dim=1)\n",
        "            ys.append(yb.cpu().numpy())\n",
        "            ps.append(prob.cpu().numpy())\n",
        "    y_true = np.concatenate(ys); p = np.concatenate(ps)\n",
        "    return y_true, p.argmax(1), p\n",
        "\n",
        "best_val = np.inf\n",
        "wait = 0\n",
        "best_path = os.path.join(OUT_DIR, \"tcn_best.pt\")\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    running = 0.0\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.amp.autocast(\"cuda\", enabled=torch.cuda.is_available()):\n",
        "            logits = model(xb)\n",
        "            loss = criterion(logits, yb)\n",
        "        amp_scaler.scale(loss).backward()\n",
        "        # clip grads for stability\n",
        "        amp_scaler.unscale_(optimizer)\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        amp_scaler.step(optimizer)\n",
        "        amp_scaler.update()\n",
        "        running += loss.item() * xb.size(0)\n",
        "\n",
        "    train_loss = running / len(train_ds)\n",
        "    sched.step()\n",
        "\n",
        "    yv_true, yv_pred, yv_proba = eval_loader(val_loader)\n",
        "    val_loss = log_loss(yv_true, yv_proba, labels=np.arange(num_classes))\n",
        "\n",
        "    if val_loss < best_val:\n",
        "        best_val, wait = val_loss, 0\n",
        "\n",
        "        # Save weights\n",
        "        torch.save({\"model\": model.state_dict()}, best_path)\n",
        "\n",
        "        # Save the *feature* scaler stats used earlier\n",
        "        with open(os.path.join(OUT_DIR, \"tcn_scaler.json\"), \"w\") as f:\n",
        "            json.dump({\n",
        "                \"mean\": std_scaler.mean_.tolist(),\n",
        "                \"scale\": std_scaler.scale_.tolist(),\n",
        "                \"feature_names\": feature_names,\n",
        "                \"seq_len\": SEQ_LEN\n",
        "            }, f, indent=2)\n",
        "    else:\n",
        "        wait += 1\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} | train_loss {train_loss:.4f} | val_logloss {val_loss:.4f} | best {best_val:.4f} | wait {wait}/{PATIENCE}\")\n",
        "    if wait >= PATIENCE:\n",
        "        print(\"Early stopping.\")\n",
        "        break\n",
        "\n",
        "print(\"Best val logloss:\", round(best_val, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utKpp_s5C3aW",
        "outputId": "1f6e52da-7a02-4fbb-8dcf-38256925e27d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | train_loss 0.9722 | val_logloss 0.9441 | best 0.9441 | wait 0/200\n",
            "Epoch 02 | train_loss 0.9104 | val_logloss 1.0309 | best 0.9441 | wait 1/200\n",
            "Epoch 03 | train_loss 0.8774 | val_logloss 1.2436 | best 0.9441 | wait 2/200\n",
            "Epoch 04 | train_loss 0.8448 | val_logloss 1.3143 | best 0.9441 | wait 3/200\n",
            "Epoch 05 | train_loss 0.7985 | val_logloss 0.9581 | best 0.9441 | wait 4/200\n",
            "Epoch 06 | train_loss 0.7582 | val_logloss 1.1621 | best 0.9441 | wait 5/200\n",
            "Epoch 07 | train_loss 0.7431 | val_logloss 1.0162 | best 0.9441 | wait 6/200\n",
            "Epoch 08 | train_loss 0.7327 | val_logloss 0.9666 | best 0.9441 | wait 7/200\n",
            "Epoch 09 | train_loss 0.7184 | val_logloss 1.0141 | best 0.9441 | wait 8/200\n",
            "Epoch 10 | train_loss 0.7351 | val_logloss 1.1022 | best 0.9441 | wait 9/200\n",
            "Epoch 11 | train_loss 0.7033 | val_logloss 1.0253 | best 0.9441 | wait 10/200\n",
            "Epoch 12 | train_loss 0.7142 | val_logloss 1.3730 | best 0.9441 | wait 11/200\n",
            "Epoch 13 | train_loss 0.6846 | val_logloss 1.1231 | best 0.9441 | wait 12/200\n",
            "Epoch 14 | train_loss 0.6924 | val_logloss 1.3125 | best 0.9441 | wait 13/200\n",
            "Epoch 15 | train_loss 0.6776 | val_logloss 1.2521 | best 0.9441 | wait 14/200\n",
            "Epoch 16 | train_loss 0.6864 | val_logloss 1.3134 | best 0.9441 | wait 15/200\n",
            "Epoch 17 | train_loss 0.7015 | val_logloss 1.6210 | best 0.9441 | wait 16/200\n",
            "Epoch 18 | train_loss 0.6690 | val_logloss 1.4205 | best 0.9441 | wait 17/200\n",
            "Epoch 19 | train_loss 0.6622 | val_logloss 1.3656 | best 0.9441 | wait 18/200\n",
            "Epoch 20 | train_loss 0.6787 | val_logloss 1.3278 | best 0.9441 | wait 19/200\n",
            "Epoch 21 | train_loss 0.6895 | val_logloss 0.9938 | best 0.9441 | wait 20/200\n",
            "Epoch 22 | train_loss 0.6651 | val_logloss 1.5354 | best 0.9441 | wait 21/200\n",
            "Epoch 23 | train_loss 0.6496 | val_logloss 1.2433 | best 0.9441 | wait 22/200\n",
            "Epoch 24 | train_loss 0.6566 | val_logloss 1.9990 | best 0.9441 | wait 23/200\n",
            "Epoch 25 | train_loss 0.6778 | val_logloss 1.3968 | best 0.9441 | wait 24/200\n",
            "Epoch 26 | train_loss 0.6373 | val_logloss 1.8995 | best 0.9441 | wait 25/200\n",
            "Epoch 27 | train_loss 0.6431 | val_logloss 1.2113 | best 0.9441 | wait 26/200\n",
            "Epoch 28 | train_loss 0.6188 | val_logloss 1.0855 | best 0.9441 | wait 27/200\n",
            "Epoch 29 | train_loss 0.6113 | val_logloss 1.6442 | best 0.9441 | wait 28/200\n",
            "Epoch 30 | train_loss 0.6000 | val_logloss 1.0735 | best 0.9441 | wait 29/200\n",
            "Epoch 31 | train_loss 0.6148 | val_logloss 1.8142 | best 0.9441 | wait 30/200\n",
            "Epoch 32 | train_loss 0.6101 | val_logloss 1.2619 | best 0.9441 | wait 31/200\n",
            "Epoch 33 | train_loss 0.6029 | val_logloss 0.9909 | best 0.9441 | wait 32/200\n",
            "Epoch 34 | train_loss 0.6014 | val_logloss 0.9019 | best 0.9019 | wait 0/200\n",
            "Epoch 35 | train_loss 0.5909 | val_logloss 0.9650 | best 0.9019 | wait 1/200\n",
            "Epoch 36 | train_loss 0.6002 | val_logloss 1.1350 | best 0.9019 | wait 2/200\n",
            "Epoch 37 | train_loss 0.5839 | val_logloss 1.0851 | best 0.9019 | wait 3/200\n",
            "Epoch 38 | train_loss 0.5864 | val_logloss 1.6301 | best 0.9019 | wait 4/200\n",
            "Epoch 39 | train_loss 0.5783 | val_logloss 0.8596 | best 0.8596 | wait 0/200\n",
            "Epoch 40 | train_loss 0.5837 | val_logloss 1.8404 | best 0.8596 | wait 1/200\n",
            "Epoch 41 | train_loss 0.5888 | val_logloss 1.4568 | best 0.8596 | wait 2/200\n",
            "Epoch 42 | train_loss 0.5506 | val_logloss 1.2565 | best 0.8596 | wait 3/200\n",
            "Epoch 43 | train_loss 0.5692 | val_logloss 1.4325 | best 0.8596 | wait 4/200\n",
            "Epoch 44 | train_loss 0.5348 | val_logloss 1.5594 | best 0.8596 | wait 5/200\n",
            "Epoch 45 | train_loss 0.5614 | val_logloss 1.0555 | best 0.8596 | wait 6/200\n",
            "Epoch 46 | train_loss 0.5355 | val_logloss 1.1659 | best 0.8596 | wait 7/200\n",
            "Epoch 47 | train_loss 0.5374 | val_logloss 1.5182 | best 0.8596 | wait 8/200\n",
            "Epoch 48 | train_loss 0.5713 | val_logloss 1.4939 | best 0.8596 | wait 9/200\n",
            "Epoch 49 | train_loss 0.5537 | val_logloss 1.6132 | best 0.8596 | wait 10/200\n",
            "Epoch 50 | train_loss 0.5123 | val_logloss 1.1702 | best 0.8596 | wait 11/200\n",
            "Epoch 51 | train_loss 0.5134 | val_logloss 1.4701 | best 0.8596 | wait 12/200\n",
            "Epoch 52 | train_loss 0.5266 | val_logloss 1.1279 | best 0.8596 | wait 13/200\n",
            "Epoch 53 | train_loss 0.5193 | val_logloss 1.2133 | best 0.8596 | wait 14/200\n",
            "Epoch 54 | train_loss 0.4903 | val_logloss 1.2386 | best 0.8596 | wait 15/200\n",
            "Epoch 55 | train_loss 0.4837 | val_logloss 1.1225 | best 0.8596 | wait 16/200\n",
            "Epoch 56 | train_loss 0.4707 | val_logloss 1.3981 | best 0.8596 | wait 17/200\n",
            "Epoch 57 | train_loss 0.4868 | val_logloss 1.6491 | best 0.8596 | wait 18/200\n",
            "Epoch 58 | train_loss 0.4810 | val_logloss 1.2895 | best 0.8596 | wait 19/200\n",
            "Epoch 59 | train_loss 0.4800 | val_logloss 1.2812 | best 0.8596 | wait 20/200\n",
            "Epoch 60 | train_loss 0.4654 | val_logloss 1.3272 | best 0.8596 | wait 21/200\n",
            "Epoch 61 | train_loss 0.4638 | val_logloss 1.2246 | best 0.8596 | wait 22/200\n",
            "Epoch 62 | train_loss 0.4616 | val_logloss 1.7606 | best 0.8596 | wait 23/200\n",
            "Epoch 63 | train_loss 0.4671 | val_logloss 1.0278 | best 0.8596 | wait 24/200\n",
            "Epoch 64 | train_loss 0.4455 | val_logloss 1.6670 | best 0.8596 | wait 25/200\n",
            "Epoch 65 | train_loss 0.4242 | val_logloss 1.4933 | best 0.8596 | wait 26/200\n",
            "Epoch 66 | train_loss 0.4172 | val_logloss 1.5115 | best 0.8596 | wait 27/200\n",
            "Epoch 67 | train_loss 0.4109 | val_logloss 1.6480 | best 0.8596 | wait 28/200\n",
            "Epoch 68 | train_loss 0.4144 | val_logloss 1.4771 | best 0.8596 | wait 29/200\n",
            "Epoch 69 | train_loss 0.3884 | val_logloss 2.0744 | best 0.8596 | wait 30/200\n",
            "Epoch 70 | train_loss 0.4171 | val_logloss 1.6410 | best 0.8596 | wait 31/200\n",
            "Epoch 71 | train_loss 0.4150 | val_logloss 1.3645 | best 0.8596 | wait 32/200\n",
            "Epoch 72 | train_loss 0.4062 | val_logloss 1.9365 | best 0.8596 | wait 33/200\n",
            "Epoch 73 | train_loss 0.3948 | val_logloss 1.7812 | best 0.8596 | wait 34/200\n",
            "Epoch 74 | train_loss 0.3817 | val_logloss 1.8730 | best 0.8596 | wait 35/200\n",
            "Epoch 75 | train_loss 0.3606 | val_logloss 1.5928 | best 0.8596 | wait 36/200\n",
            "Epoch 76 | train_loss 0.3777 | val_logloss 1.7831 | best 0.8596 | wait 37/200\n",
            "Epoch 77 | train_loss 0.3840 | val_logloss 2.3651 | best 0.8596 | wait 38/200\n",
            "Epoch 78 | train_loss 0.3888 | val_logloss 2.6590 | best 0.8596 | wait 39/200\n",
            "Epoch 79 | train_loss 0.3634 | val_logloss 2.0079 | best 0.8596 | wait 40/200\n",
            "Epoch 80 | train_loss 0.3507 | val_logloss 1.8774 | best 0.8596 | wait 41/200\n",
            "Epoch 81 | train_loss 0.3599 | val_logloss 1.3026 | best 0.8596 | wait 42/200\n",
            "Epoch 82 | train_loss 0.3287 | val_logloss 1.7249 | best 0.8596 | wait 43/200\n",
            "Epoch 83 | train_loss 0.3327 | val_logloss 1.6328 | best 0.8596 | wait 44/200\n",
            "Epoch 84 | train_loss 0.3436 | val_logloss 1.5000 | best 0.8596 | wait 45/200\n",
            "Epoch 85 | train_loss 0.3343 | val_logloss 2.3682 | best 0.8596 | wait 46/200\n",
            "Epoch 86 | train_loss 0.3074 | val_logloss 1.8021 | best 0.8596 | wait 47/200\n",
            "Epoch 87 | train_loss 0.3492 | val_logloss 1.6017 | best 0.8596 | wait 48/200\n",
            "Epoch 88 | train_loss 0.3219 | val_logloss 2.3093 | best 0.8596 | wait 49/200\n",
            "Epoch 89 | train_loss 0.2973 | val_logloss 1.4946 | best 0.8596 | wait 50/200\n",
            "Epoch 90 | train_loss 0.3433 | val_logloss 2.3438 | best 0.8596 | wait 51/200\n",
            "Epoch 91 | train_loss 0.2938 | val_logloss 2.7134 | best 0.8596 | wait 52/200\n",
            "Epoch 92 | train_loss 0.3059 | val_logloss 1.8878 | best 0.8596 | wait 53/200\n",
            "Epoch 93 | train_loss 0.2895 | val_logloss 2.3660 | best 0.8596 | wait 54/200\n",
            "Epoch 94 | train_loss 0.2931 | val_logloss 2.4851 | best 0.8596 | wait 55/200\n",
            "Epoch 95 | train_loss 0.3036 | val_logloss 2.2678 | best 0.8596 | wait 56/200\n",
            "Epoch 96 | train_loss 0.2884 | val_logloss 2.4443 | best 0.8596 | wait 57/200\n",
            "Epoch 97 | train_loss 0.2811 | val_logloss 2.5399 | best 0.8596 | wait 58/200\n",
            "Epoch 98 | train_loss 0.2610 | val_logloss 1.6429 | best 0.8596 | wait 59/200\n",
            "Epoch 99 | train_loss 0.2916 | val_logloss 1.3505 | best 0.8596 | wait 60/200\n",
            "Epoch 100 | train_loss 0.2652 | val_logloss 2.0859 | best 0.8596 | wait 61/200\n",
            "Epoch 101 | train_loss 0.2636 | val_logloss 2.7003 | best 0.8596 | wait 62/200\n",
            "Epoch 102 | train_loss 0.2596 | val_logloss 1.9723 | best 0.8596 | wait 63/200\n",
            "Epoch 103 | train_loss 0.2381 | val_logloss 1.7278 | best 0.8596 | wait 64/200\n",
            "Epoch 104 | train_loss 0.2759 | val_logloss 2.1541 | best 0.8596 | wait 65/200\n",
            "Epoch 105 | train_loss 0.2590 | val_logloss 1.9256 | best 0.8596 | wait 66/200\n",
            "Epoch 106 | train_loss 0.2523 | val_logloss 2.1887 | best 0.8596 | wait 67/200\n",
            "Epoch 107 | train_loss 0.2625 | val_logloss 2.0689 | best 0.8596 | wait 68/200\n",
            "Epoch 108 | train_loss 0.2195 | val_logloss 2.5495 | best 0.8596 | wait 69/200\n",
            "Epoch 109 | train_loss 0.2531 | val_logloss 3.5561 | best 0.8596 | wait 70/200\n",
            "Epoch 110 | train_loss 0.2620 | val_logloss 2.5217 | best 0.8596 | wait 71/200\n",
            "Epoch 111 | train_loss 0.2314 | val_logloss 2.4617 | best 0.8596 | wait 72/200\n",
            "Epoch 112 | train_loss 0.2063 | val_logloss 2.2811 | best 0.8596 | wait 73/200\n",
            "Epoch 113 | train_loss 0.2214 | val_logloss 2.6528 | best 0.8596 | wait 74/200\n",
            "Epoch 114 | train_loss 0.2522 | val_logloss 2.0311 | best 0.8596 | wait 75/200\n",
            "Epoch 115 | train_loss 0.2417 | val_logloss 2.6882 | best 0.8596 | wait 76/200\n",
            "Epoch 116 | train_loss 0.2118 | val_logloss 3.5363 | best 0.8596 | wait 77/200\n",
            "Epoch 117 | train_loss 0.2251 | val_logloss 3.3604 | best 0.8596 | wait 78/200\n",
            "Epoch 118 | train_loss 0.2098 | val_logloss 2.9500 | best 0.8596 | wait 79/200\n",
            "Epoch 119 | train_loss 0.2170 | val_logloss 2.7204 | best 0.8596 | wait 80/200\n",
            "Epoch 120 | train_loss 0.2112 | val_logloss 3.3352 | best 0.8596 | wait 81/200\n",
            "Epoch 121 | train_loss 0.2462 | val_logloss 3.3401 | best 0.8596 | wait 82/200\n",
            "Epoch 122 | train_loss 0.2326 | val_logloss 2.9269 | best 0.8596 | wait 83/200\n",
            "Epoch 123 | train_loss 0.1940 | val_logloss 3.1859 | best 0.8596 | wait 84/200\n",
            "Epoch 124 | train_loss 0.2458 | val_logloss 3.2753 | best 0.8596 | wait 85/200\n",
            "Epoch 125 | train_loss 0.1825 | val_logloss 2.8414 | best 0.8596 | wait 86/200\n",
            "Epoch 126 | train_loss 0.2215 | val_logloss 3.2517 | best 0.8596 | wait 87/200\n",
            "Epoch 127 | train_loss 0.1899 | val_logloss 2.6567 | best 0.8596 | wait 88/200\n",
            "Epoch 128 | train_loss 0.2153 | val_logloss 2.9894 | best 0.8596 | wait 89/200\n",
            "Epoch 129 | train_loss 0.2104 | val_logloss 2.6587 | best 0.8596 | wait 90/200\n",
            "Epoch 130 | train_loss 0.1935 | val_logloss 3.0096 | best 0.8596 | wait 91/200\n",
            "Epoch 131 | train_loss 0.1853 | val_logloss 2.2543 | best 0.8596 | wait 92/200\n",
            "Epoch 132 | train_loss 0.1861 | val_logloss 3.5236 | best 0.8596 | wait 93/200\n",
            "Epoch 133 | train_loss 0.1844 | val_logloss 2.9596 | best 0.8596 | wait 94/200\n",
            "Epoch 134 | train_loss 0.1980 | val_logloss 3.2326 | best 0.8596 | wait 95/200\n",
            "Epoch 135 | train_loss 0.1824 | val_logloss 3.1025 | best 0.8596 | wait 96/200\n",
            "Epoch 136 | train_loss 0.1981 | val_logloss 3.8526 | best 0.8596 | wait 97/200\n",
            "Epoch 137 | train_loss 0.1793 | val_logloss 3.7254 | best 0.8596 | wait 98/200\n",
            "Epoch 138 | train_loss 0.1858 | val_logloss 3.2458 | best 0.8596 | wait 99/200\n",
            "Epoch 139 | train_loss 0.1787 | val_logloss 3.7071 | best 0.8596 | wait 100/200\n",
            "Epoch 140 | train_loss 0.1839 | val_logloss 3.7563 | best 0.8596 | wait 101/200\n",
            "Epoch 141 | train_loss 0.1872 | val_logloss 3.7067 | best 0.8596 | wait 102/200\n",
            "Epoch 142 | train_loss 0.1619 | val_logloss 3.4833 | best 0.8596 | wait 103/200\n",
            "Epoch 143 | train_loss 0.1785 | val_logloss 4.0405 | best 0.8596 | wait 104/200\n",
            "Epoch 144 | train_loss 0.1799 | val_logloss 2.8966 | best 0.8596 | wait 105/200\n",
            "Epoch 145 | train_loss 0.1753 | val_logloss 3.5377 | best 0.8596 | wait 106/200\n",
            "Epoch 146 | train_loss 0.1551 | val_logloss 4.1519 | best 0.8596 | wait 107/200\n",
            "Epoch 147 | train_loss 0.1624 | val_logloss 3.9059 | best 0.8596 | wait 108/200\n",
            "Epoch 148 | train_loss 0.1762 | val_logloss 3.2656 | best 0.8596 | wait 109/200\n",
            "Epoch 149 | train_loss 0.1620 | val_logloss 3.5334 | best 0.8596 | wait 110/200\n",
            "Epoch 150 | train_loss 0.1688 | val_logloss 4.7034 | best 0.8596 | wait 111/200\n",
            "Epoch 151 | train_loss 0.1565 | val_logloss 3.5150 | best 0.8596 | wait 112/200\n",
            "Epoch 152 | train_loss 0.2217 | val_logloss 3.2059 | best 0.8596 | wait 113/200\n",
            "Epoch 153 | train_loss 0.1607 | val_logloss 3.4796 | best 0.8596 | wait 114/200\n",
            "Epoch 154 | train_loss 0.1499 | val_logloss 3.9160 | best 0.8596 | wait 115/200\n",
            "Epoch 155 | train_loss 0.1423 | val_logloss 3.9305 | best 0.8596 | wait 116/200\n",
            "Epoch 156 | train_loss 0.1508 | val_logloss 3.3303 | best 0.8596 | wait 117/200\n",
            "Epoch 157 | train_loss 0.1278 | val_logloss 3.6463 | best 0.8596 | wait 118/200\n",
            "Epoch 158 | train_loss 0.1460 | val_logloss 3.9693 | best 0.8596 | wait 119/200\n",
            "Epoch 159 | train_loss 0.1578 | val_logloss 3.5466 | best 0.8596 | wait 120/200\n",
            "Epoch 160 | train_loss 0.1457 | val_logloss 3.7343 | best 0.8596 | wait 121/200\n",
            "Epoch 161 | train_loss 0.1598 | val_logloss 2.9236 | best 0.8596 | wait 122/200\n",
            "Epoch 162 | train_loss 0.1477 | val_logloss 4.2771 | best 0.8596 | wait 123/200\n",
            "Epoch 163 | train_loss 0.1414 | val_logloss 4.3339 | best 0.8596 | wait 124/200\n",
            "Epoch 164 | train_loss 0.1241 | val_logloss 4.4423 | best 0.8596 | wait 125/200\n",
            "Epoch 165 | train_loss 0.1426 | val_logloss 4.1875 | best 0.8596 | wait 126/200\n",
            "Epoch 166 | train_loss 0.1393 | val_logloss 3.5624 | best 0.8596 | wait 127/200\n",
            "Epoch 167 | train_loss 0.1436 | val_logloss 2.6415 | best 0.8596 | wait 128/200\n",
            "Epoch 168 | train_loss 0.1253 | val_logloss 3.2383 | best 0.8596 | wait 129/200\n",
            "Epoch 169 | train_loss 0.1156 | val_logloss 4.3752 | best 0.8596 | wait 130/200\n",
            "Epoch 170 | train_loss 0.1333 | val_logloss 4.3405 | best 0.8596 | wait 131/200\n",
            "Epoch 171 | train_loss 0.1358 | val_logloss 4.3821 | best 0.8596 | wait 132/200\n",
            "Epoch 172 | train_loss 0.1480 | val_logloss 3.9692 | best 0.8596 | wait 133/200\n",
            "Epoch 173 | train_loss 0.1313 | val_logloss 5.1065 | best 0.8596 | wait 134/200\n",
            "Epoch 174 | train_loss 0.1270 | val_logloss 3.9536 | best 0.8596 | wait 135/200\n",
            "Epoch 175 | train_loss 0.1371 | val_logloss 4.3049 | best 0.8596 | wait 136/200\n",
            "Epoch 176 | train_loss 0.1307 | val_logloss 4.5033 | best 0.8596 | wait 137/200\n",
            "Epoch 177 | train_loss 0.1356 | val_logloss 4.2819 | best 0.8596 | wait 138/200\n",
            "Epoch 178 | train_loss 0.1218 | val_logloss 4.1368 | best 0.8596 | wait 139/200\n",
            "Epoch 179 | train_loss 0.1322 | val_logloss 4.4488 | best 0.8596 | wait 140/200\n",
            "Epoch 180 | train_loss 0.1430 | val_logloss 5.9029 | best 0.8596 | wait 141/200\n",
            "Epoch 181 | train_loss 0.1348 | val_logloss 4.9721 | best 0.8596 | wait 142/200\n",
            "Epoch 182 | train_loss 0.1169 | val_logloss 5.8364 | best 0.8596 | wait 143/200\n",
            "Epoch 183 | train_loss 0.1323 | val_logloss 4.5616 | best 0.8596 | wait 144/200\n",
            "Epoch 184 | train_loss 0.1145 | val_logloss 4.3863 | best 0.8596 | wait 145/200\n",
            "Epoch 185 | train_loss 0.1240 | val_logloss 3.6240 | best 0.8596 | wait 146/200\n",
            "Epoch 186 | train_loss 0.1153 | val_logloss 4.8724 | best 0.8596 | wait 147/200\n",
            "Epoch 187 | train_loss 0.1118 | val_logloss 4.4452 | best 0.8596 | wait 148/200\n",
            "Epoch 188 | train_loss 0.1207 | val_logloss 4.2450 | best 0.8596 | wait 149/200\n",
            "Epoch 189 | train_loss 0.1116 | val_logloss 3.8261 | best 0.8596 | wait 150/200\n",
            "Epoch 190 | train_loss 0.1268 | val_logloss 4.0789 | best 0.8596 | wait 151/200\n",
            "Epoch 191 | train_loss 0.1047 | val_logloss 5.1006 | best 0.8596 | wait 152/200\n",
            "Epoch 192 | train_loss 0.1013 | val_logloss 4.5023 | best 0.8596 | wait 153/200\n",
            "Epoch 193 | train_loss 0.1094 | val_logloss 4.0051 | best 0.8596 | wait 154/200\n",
            "Epoch 194 | train_loss 0.1172 | val_logloss 5.0235 | best 0.8596 | wait 155/200\n",
            "Epoch 195 | train_loss 0.1155 | val_logloss 4.3039 | best 0.8596 | wait 156/200\n",
            "Epoch 196 | train_loss 0.1084 | val_logloss 4.8554 | best 0.8596 | wait 157/200\n",
            "Epoch 197 | train_loss 0.1005 | val_logloss 4.6526 | best 0.8596 | wait 158/200\n",
            "Epoch 198 | train_loss 0.1268 | val_logloss 3.8848 | best 0.8596 | wait 159/200\n",
            "Epoch 199 | train_loss 0.1278 | val_logloss 4.0197 | best 0.8596 | wait 160/200\n",
            "Epoch 200 | train_loss 0.1037 | val_logloss 4.4208 | best 0.8596 | wait 161/200\n",
            "Epoch 201 | train_loss 0.0973 | val_logloss 4.7520 | best 0.8596 | wait 162/200\n",
            "Epoch 202 | train_loss 0.0886 | val_logloss 5.5126 | best 0.8596 | wait 163/200\n",
            "Epoch 203 | train_loss 0.0910 | val_logloss 4.8445 | best 0.8596 | wait 164/200\n",
            "Epoch 204 | train_loss 0.0814 | val_logloss 4.1780 | best 0.8596 | wait 165/200\n",
            "Epoch 205 | train_loss 0.0934 | val_logloss 4.1573 | best 0.8596 | wait 166/200\n",
            "Epoch 206 | train_loss 0.0935 | val_logloss 4.5037 | best 0.8596 | wait 167/200\n",
            "Epoch 207 | train_loss 0.0937 | val_logloss 4.5417 | best 0.8596 | wait 168/200\n",
            "Epoch 208 | train_loss 0.0960 | val_logloss 4.4688 | best 0.8596 | wait 169/200\n",
            "Epoch 209 | train_loss 0.1051 | val_logloss 4.5342 | best 0.8596 | wait 170/200\n",
            "Epoch 210 | train_loss 0.0959 | val_logloss 4.6378 | best 0.8596 | wait 171/200\n",
            "Epoch 211 | train_loss 0.0972 | val_logloss 4.8732 | best 0.8596 | wait 172/200\n",
            "Epoch 212 | train_loss 0.0983 | val_logloss 4.3412 | best 0.8596 | wait 173/200\n",
            "Epoch 213 | train_loss 0.1246 | val_logloss 5.2425 | best 0.8596 | wait 174/200\n",
            "Epoch 214 | train_loss 0.0890 | val_logloss 5.6854 | best 0.8596 | wait 175/200\n",
            "Epoch 215 | train_loss 0.0987 | val_logloss 4.0098 | best 0.8596 | wait 176/200\n",
            "Epoch 216 | train_loss 0.1268 | val_logloss 3.9051 | best 0.8596 | wait 177/200\n",
            "Epoch 217 | train_loss 0.0895 | val_logloss 4.4675 | best 0.8596 | wait 178/200\n",
            "Epoch 218 | train_loss 0.0924 | val_logloss 4.7376 | best 0.8596 | wait 179/200\n",
            "Epoch 219 | train_loss 0.0839 | val_logloss 4.7809 | best 0.8596 | wait 180/200\n",
            "Epoch 220 | train_loss 0.0858 | val_logloss 4.5372 | best 0.8596 | wait 181/200\n",
            "Epoch 221 | train_loss 0.0940 | val_logloss 3.6686 | best 0.8596 | wait 182/200\n",
            "Epoch 222 | train_loss 0.0924 | val_logloss 4.7173 | best 0.8596 | wait 183/200\n",
            "Epoch 223 | train_loss 0.0795 | val_logloss 4.8611 | best 0.8596 | wait 184/200\n",
            "Epoch 224 | train_loss 0.0907 | val_logloss 4.4593 | best 0.8596 | wait 185/200\n",
            "Epoch 225 | train_loss 0.0716 | val_logloss 4.8719 | best 0.8596 | wait 186/200\n",
            "Epoch 226 | train_loss 0.0686 | val_logloss 4.9316 | best 0.8596 | wait 187/200\n",
            "Epoch 227 | train_loss 0.0897 | val_logloss 4.6337 | best 0.8596 | wait 188/200\n",
            "Epoch 228 | train_loss 0.0798 | val_logloss 4.2703 | best 0.8596 | wait 189/200\n",
            "Epoch 229 | train_loss 0.0780 | val_logloss 4.7507 | best 0.8596 | wait 190/200\n",
            "Epoch 230 | train_loss 0.0911 | val_logloss 4.4950 | best 0.8596 | wait 191/200\n",
            "Epoch 231 | train_loss 0.0815 | val_logloss 4.7111 | best 0.8596 | wait 192/200\n",
            "Epoch 232 | train_loss 0.0741 | val_logloss 4.1216 | best 0.8596 | wait 193/200\n",
            "Epoch 233 | train_loss 0.0733 | val_logloss 4.9934 | best 0.8596 | wait 194/200\n",
            "Epoch 234 | train_loss 0.0838 | val_logloss 4.1454 | best 0.8596 | wait 195/200\n",
            "Epoch 235 | train_loss 0.0627 | val_logloss 4.9485 | best 0.8596 | wait 196/200\n",
            "Epoch 236 | train_loss 0.0825 | val_logloss 4.0243 | best 0.8596 | wait 197/200\n",
            "Epoch 237 | train_loss 0.0998 | val_logloss 4.1960 | best 0.8596 | wait 198/200\n",
            "Epoch 238 | train_loss 0.0886 | val_logloss 3.9275 | best 0.8596 | wait 199/200\n",
            "Epoch 239 | train_loss 0.0620 | val_logloss 4.9936 | best 0.8596 | wait 200/200\n",
            "Early stopping.\n",
            "Best val logloss: 0.8596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt = torch.load(best_path, map_location=device)\n",
        "model.load_state_dict(ckpt[\"model\"])\n",
        "\n",
        "ytest_true, ytest_pred, ytest_proba = eval_loader(test_loader)\n",
        "test_balacc = balanced_accuracy_score(ytest_true, ytest_pred)\n",
        "test_f1m    = f1_score(ytest_true, ytest_pred, average=\"macro\")\n",
        "test_rep    = classification_report(ytest_true, ytest_pred, digits=3, zero_division=0)\n",
        "test_cm     = confusion_matrix(ytest_true, ytest_pred, labels=np.arange(num_classes))\n",
        "test_ll     = log_loss(ytest_true, ytest_proba, labels=np.arange(num_classes))\n",
        "\n",
        "print(\"\\n=== TEST RESULTS (TCN) ===\")\n",
        "print(\"LogLoss:\", round(test_ll, 4))\n",
        "print(\"Balanced Acc:\", round(test_balacc, 4))\n",
        "print(\"Macro F1:\", round(test_f1m, 4))\n",
        "print(\"\\nClassification Report:\\n\", test_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4UWKUXlDBgL",
        "outputId": "f21b7a7c-e834-4cb7-ba39-eae1c7f63458"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== TEST RESULTS (TCN) ===\n",
            "LogLoss: 1.8158\n",
            "Balanced Acc: 0.4347\n",
            "Macro F1: 0.4106\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0      0.542     0.279     0.368       326\n",
            "           1      0.382     0.573     0.458       267\n",
            "           2      0.367     0.452     0.405       104\n",
            "\n",
            "    accuracy                          0.418       697\n",
            "   macro avg      0.430     0.435     0.411       697\n",
            "weighted avg      0.454     0.418     0.408       697\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(os.path.join(OUT_DIR, \"tcn_test_metrics.json\"), \"w\") as f:\n",
        "    json.dump({\"logloss\": float(test_ll), \"balanced_acc\": float(test_balacc), \"macro_f1\": float(test_f1m)}, f, indent=2)\n",
        "\n",
        "# Predictions\n",
        "pd.DataFrame({\"date\": dates_te.date, \"y_true\": ytest_true, \"y_pred\": ytest_pred}).to_csv(\n",
        "    os.path.join(OUT_DIR, \"tcn_test_predictions.csv\"), index=False)\n",
        "\n",
        "# Confusion matrix plot\n",
        "fig, ax = plt.subplots(figsize=(4,4), dpi=150)\n",
        "im = ax.imshow(test_cm, interpolation=\"nearest\")\n",
        "ax.set_title(\"Confusion Matrix — TCN (Test)\")\n",
        "ax.set_xticks(range(num_classes)); ax.set_yticks(range(num_classes))\n",
        "ax.set_xticklabels(range(num_classes)); ax.set_yticklabels(range(num_classes))\n",
        "ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\")\n",
        "for i in range(test_cm.shape[0]):\n",
        "    for j in range(test_cm.shape[1]):\n",
        "        ax.text(j, i, test_cm[i, j], ha=\"center\", va=\"center\")\n",
        "fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUT_DIR, \"tcn_confusion_matrix.png\"))\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n✅ Saved in {OUT_DIR}:\")\n",
        "print(\" - tcn_best.pt (weights)\")\n",
        "print(\" - tcn_scaler.json (means/scales + feature names + seq_len)\")\n",
        "print(\" - tcn_test_metrics.json\")\n",
        "print(\" - tcn_test_predictions.csv\")\n",
        "print(\" - tcn_confusion_matrix.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "id": "aLRQvuMwKpTt",
        "outputId": "7fab88c5-16c2-4918-e191-2fe1cd866989"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Saved in /content/drive/MyDrive/Regime_pred/Models/Deep_TCN:\n",
            " - tcn_best.pt (weights)\n",
            " - tcn_scaler.json (means/scales + feature names + seq_len)\n",
            " - tcn_test_metrics.json\n",
            " - tcn_test_predictions.csv\n",
            " - tcn_confusion_matrix.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZLrDFZ2zKxmA"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}